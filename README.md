# 🖼️ Image Classification and Adversarial Attack Testing

[CIFAR-10 / CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) (Dataset with 60000 32x32 images of 10 or 100 classes.)

❕ This project was implemented using the **Google Colaboratory** environment. It is recommended to use this environment for correct installation and correct use of packages.

## 📚 About This Project

## 🧰 Development Tools
- Python 3.12.2
- [TensorFlow]()
- [Google Colab](https://colab.research.google.com) (Jupyter Notebook)

## 📊 Results
### 1️⃣ First test:

![image](https://github.com/user-attachments/assets/c4d9544e-b5f6-4594-b6f8-6bda4ee5fca5)

### 2️⃣ Second test:
  
![image](https://github.com/user-attachments/assets/e74b08a1-33a4-4228-85f3-0599312855f5)

### 3️⃣ Third test:
  
![image](https://github.com/user-attachments/assets/9ca29754-c9f7-424b-9274-d5a4917aa8d6)

## ✍️ Conclusion

## 📂 Project Structure

📦 Image-Classification-and-Adversarial-Attack-Testing <br>
├── 📄 **README.md** -- *Project documentation <br>*
├── 📊 **ImgClassification-_and_AdvAttacks.ipynb** -- *Main notebook <br>*
└── 📂 **Models** -- *Folder with trained models <br>*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── 📄 **cifar10_73.keras** -- *Model of trained model for CIFAR-10 with 73% accuracy<br>*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── 📄 **...** -- *Other models <br>*
└── 📂 **Images** -- *Folder with images for testing <br>*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── 📄 **jelen.jpg** -- *Image of jeleń<br>*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── 📄 **...** -- *Other images <br>*

Images to testing was generated with AI ([Grok](https://x.com/i/grok))
